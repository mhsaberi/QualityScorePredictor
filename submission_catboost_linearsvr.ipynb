{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Score Prediction with Stacking Ensemble\n",
    "\n",
    "This notebook implements a stacking ensemble model to predict the `quality_score` for a manufacturing dataset. The model uses **CatBoost** and **LinearSVR** as base models, with **Linear Regression** as the meta-model. The code was used in a Kaggle competition, achieving a public leaderboard score of **0.10676**, but underperformed on the private leaderboard.\n",
    "\n",
    "## Overview\n",
    "- **Data**: Manufacturing data with features like `defect_area`, `plate_length`, `temperature`, etc.\n",
    "- **Task**: Predict `quality_score` (continuous target variable).\n",
    "- **Approach**:\n",
    "  1. Feature engineering (e.g., logarithmic transformations, time-based features).\n",
    "  2. Preprocessing (imputation, scaling).\n",
    "  3. Hyperparameter tuning with Optuna.\n",
    "  4. Stacking ensemble with CatBoost and LinearSVR.\n",
    "  5. Submission file generation.\n",
    "\n",
    "## Why Share?\n",
    "Despite poor performance on the private leaderboard (due to overfitting and non-linear data mismatches), this code serves as a learning example for stacking ensembles, feature engineering, and hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We load the training and test datasets from CSV files. The `quality_score` is the target variable in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Separate IDs and target variable\n",
    "train_ids = train_df['id']  # Store training IDs\n",
    "test_ids = test_df['id']    # Store test IDs\n",
    "target = train_df['quality_score']  # Extract target variable\n",
    "\n",
    "# Drop ID and target columns from training data, and ID from test data\n",
    "train_df = train_df.drop(['id', 'quality_score'], axis=1)\n",
    "test_df = test_df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoding\n",
    "\n",
    "We apply target encoding to `operator_id` and `machine_id` by computing the mean `quality_score` for each category. This helps encode categorical variables numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean quality_score for each operator and machine\n",
    "operator_mean = train_df.groupby('operator_id')['quality_score'].mean()\n",
    "machine_mean = train_df.groupby('machine_id')['quality_score'].mean()\n",
    "\n",
    "# Save the encodings for future use\n",
    "joblib.dump(operator_mean, 'operator_mean.pkl')\n",
    "joblib.dump(machine_mean, 'machine_mean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We create new features to capture relationships in the data:\n",
    "- Ratio-based features (e.g., `defect_per_length`).\n",
    "- Logarithmic transformation of `defect_area`.\n",
    "- Time-based features extracted from `production_date` and `production_time`.\n",
    "- Target-encoded features for `operator_id` and `machine_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_feature_engineering(df, operator_mean, machine_mean):\n",
    "    \"\"\"Apply advanced feature engineering to the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        operator_mean (pd.Series): Mean quality_score per operator.\n",
    "        machine_mean (pd.Series): Mean quality_score per machine.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed dataframe with new features.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ratio-based features\n",
    "    df['defect_per_length'] = df['defect_area'] / (df['plate_length'] + 1e-6)  # Avoid division by zero\n",
    "    df['temp_times_thickness'] = df['temperature'] * df['plate_thickness']\n",
    "    df['log_defect_area'] = np.log1p(df['defect_area'])  # Log transform defect_area\n",
    "    df['thickness_squared'] = df['plate_thickness'] ** 2\n",
    "    df['area_per_thickness'] = df['defect_area'] / (df['plate_thickness'] + 1e-6)\n",
    "    df['temp_per_length'] = df['temperature'] / (df['plate_length'] + 1e-6)\n",
    "    df['brightness_per_luminosity'] = df['brightness_index'] / (df['min_luminosity'] + 1e-6)\n",
    "    df['edge_square_ratio'] = df['edge_index'] / (df['square_index'] + 1e-6)\n",
    "    \n",
    "    # Extract time-based features\n",
    "    df['production_datetime'] = pd.to_datetime(df['production_date'] + ' ' + df['production_time'])\n",
    "    df['day_of_week'] = df['production_datetime'].dt.dayofweek\n",
    "    df['month'] = df['production_datetime'].dt.month\n",
    "    df['hour'] = df['production_datetime'].dt.hour\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['shift'] = pd.cut(df['hour'], bins=[0, 8, 16, 24], labels=[1, 2, 3], include_lowest=True)\n",
    "    \n",
    "    # Drop original datetime columns\n",
    "    df = df.drop(['production_date', 'production_time', 'production_datetime'], axis=1)\n",
    "    \n",
    "    # Apply target encoding\n",
    "    df['operator_encoded'] = df['operator_id'].map(operator_mean).fillna(operator_mean.mean())\n",
    "    df['machine_encoded'] = df['machine_id'].map(machine_mean).fillna(machine_mean.mean())\n",
    "    \n",
    "    # Drop original categorical columns\n",
    "    df = df.drop(['operator_id', 'machine_id'], axis=1)\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to both train and test sets\n",
    "train_df = advanced_feature_engineering(train_df, operator_mean, machine_mean)\n",
    "test_df = advanced_feature_engineering(test_df, operator_mean, machine_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We preprocess the data by:\n",
    "- Imputing missing values using KNN Imputer.\n",
    "- Scaling features with StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using KNN\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_df = pd.DataFrame(imputer.fit_transform(train_df), columns=train_df.columns)\n",
    "test_df = pd.DataFrame(imputer.transform(test_df), columns=test_df.columns)\n",
    "joblib.dump(imputer, 'imputer.pkl')  # Save the imputer\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "train_df_scaled = scaler.fit_transform(train_df)\n",
    "test_df_scaled = scaler.transform(test_df)\n",
    "joblib.dump(scaler, 'scaler.pkl')  # Save the scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna\n",
    "\n",
    "We use Optuna to tune hyperparameters for both base models:\n",
    "- **CatBoost**: A gradient boosting model.\n",
    "- **LinearSVR**: A linear Support Vector Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for CatBoost\n",
    "def objective_catboost(trial):\n",
    "    \"\"\"Objective function for tuning CatBoost hyperparameters.\"\"\"\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000, step=10),\n",
    "        'depth': trial.suggest_int('depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10, step=0.5),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1, step=0.1),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255, step=5)\n",
    "    }\n",
    "    model = CatBoostRegressor(**param, random_state=42, verbose=0)\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_idx, val_idx in kf.split(train_df_scaled):\n",
    "        X_train, X_val = train_df_scaled[train_idx], train_df_scaled[val_idx]\n",
    "        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "        preds = model.predict(X_val)\n",
    "        scores.append(np.sqrt(mean_squared_error(y_val, preds)))\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Define objective function for LinearSVR\n",
    "def objective_linearsvr(trial):\n",
    "    \"\"\"Objective function for tuning LinearSVR hyperparameters.\"\"\"\n",
    "    param = {\n",
    "        'C': trial.suggest_float('C', 0.01, 10.0, log=True),\n",
    "        'epsilon': trial.suggest_float('epsilon', 0.01, 0.5),\n",
    "        'max_iter': 10000\n",
    "    }\n",
    "    model = LinearSVR(**param, random_state=42)\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_idx, val_idx in kf.split(train_df_scaled):\n",
    "        X_train, X_val = train_df_scaled[train_idx], train_df_scaled[val_idx]\n",
    "        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        scores.append(np.sqrt(mean_squared_error(y_val, preds)))\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Tune CatBoost\n",
    "study_catboost = optuna.create_study(direction='minimize')\n",
    "study_catboost.optimize(objective_catboost, n_trials=50)\n",
    "best_catboost = CatBoostRegressor(**study_catboost.best_params, random_state=42, verbose=0)\n",
    "joblib.dump(best_catboost, 'catboost_model.pkl')\n",
    "print(f\"Best CatBoost params: {study_catboost.best_params}\")\n",
    "\n",
    "# Tune LinearSVR\n",
    "study_linearsvr = optuna.create_study(direction='minimize')\n",
    "study_linearsvr.optimize(objective_linearsvr, n_trials=50)\n",
    "best_linearsvr = LinearSVR(**study_linearsvr.best_params, random_state=42, max_iter=10000)\n",
    "joblib.dump(best_linearsvr, 'linearsvr_model.pkl')\n",
    "print(f\"Best LinearSVR params: {study_linearsvr.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Ensemble\n",
    "\n",
    "We use a stacking ensemble:\n",
    "- **Base Models**: CatBoost and LinearSVR.\n",
    "- **Meta-Model**: Linear Regression.\n",
    "- **Cross-Validation**: 5-fold KFold for out-of-fold predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "base_models = [\n",
    "    ('CatBoost', best_catboost),\n",
    "    ('LinearSVR', best_linearsvr)\n",
    "]\n",
    "\n",
    "# Initialize arrays for stacking\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "stacking_train = np.zeros((len(train_df_scaled), len(base_models)))\n",
    "stacking_test = np.zeros((len(test_df_scaled), len(base_models)))\n",
    "\n",
    "# Generate out-of-fold predictions for stacking\n",
    "for i, (name, model) in enumerate(base_models):\n",
    "    print(f\"Training {name}...\")\n",
    "    oof_preds = np.zeros(len(train_df_scaled))\n",
    "    test_preds = np.zeros(len(test_df_scaled))\n",
    "    for train_idx, val_idx in kf.split(train_df_scaled):\n",
    "        X_train, X_val = train_df_scaled[train_idx], train_df_scaled[val_idx]\n",
    "        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n",
    "        if name == 'CatBoost':\n",
    "            model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "        test_preds += model.predict(test_df_scaled) / kf.n_splits\n",
    "    stacking_train[:, i] = oof_preds\n",
    "    stacking_test[:, i] = test_preds\n",
    "    rmse = np.sqrt(mean_squared_error(target, oof_preds))\n",
    "    print(f\"{name} Validation RMSE: {rmse:.5f}\")\n",
    "\n",
    "# Train meta-model\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stacking_train, target)\n",
    "joblib.dump(meta_model, 'meta_model.pkl')\n",
    "\n",
    "# Generate final predictions\n",
    "final_preds = meta_model.predict(stacking_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission File\n",
    "\n",
    "We create a submission file with the predicted `quality_score` for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({'id': test_ids, 'quality_score': final_preds})\n",
    "submission_df.to_csv('catboost_linearsvr_submission.csv', index=False)\n",
    "print(\"Submission file 'catboost_linearsvr_submission.csv' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function for New Data\n",
    "\n",
    "This function allows predicting `quality_score` for new data using the trained stacking ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_data(new_data, base_models, meta_model_path='meta_model.pkl', \n",
    "                     imputer_path='imputer.pkl', scaler_path='scaler.pkl', \n",
    "                     operator_mean_path='operator_mean.pkl', machine_mean_path='machine_mean.pkl'):\n",
    "    \"\"\"Predict quality_score for new data using the Stacking Ensemble.\n",
    "    \n",
    "    Args:\n",
    "        new_data (pd.DataFrame): New data to predict.\n",
    "        base_models (list): List of trained base models.\n",
    "        meta_model_path (str): Path to meta-model file.\n",
    "        imputer_path (str): Path to Imputer file.\n",
    "        scaler_path (str): Path to Scaler file.\n",
    "        operator_mean_path (str): Path to Target Encoding for operator_id.\n",
    "        machine_mean_path (str): Path to Target Encoding for machine_id.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame or np.array: Predicted quality_scores.\n",
    "    \"\"\"\n",
    "    # Load saved preprocessing objects\n",
    "    meta_model = joblib.load(meta_model_path)\n",
    "    imputer = joblib.load(imputer_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    operator_mean = joblib.load(operator_mean_path)\n",
    "    machine_mean = joblib.load(machine_mean_path)\n",
    "\n",
    "    # Extract IDs if present\n",
    "    new_ids = new_data['id'] if 'id' in new_data else None\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    new_data = advanced_feature_engineering(new_data, operator_mean, machine_mean)\n",
    "    \n",
    "    # Preprocess new data\n",
    "    new_data = pd.DataFrame(imputer.transform(new_data), columns=new_data.columns)\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    \n",
    "    # Generate predictions from base models\n",
    "    stacking_new = np.zeros((len(new_data_scaled), len(base_models)))\n",
    "    for i, (name, model) in enumerate(base_models):\n",
    "        stacking_new[:, i] = model.predict(new_data_scaled)\n",
    "    \n",
    "    # Predict with meta-model\n",
    "    predictions = meta_model.predict(stacking_new)\n",
    "    \n",
    "    # Return predictions with IDs if provided\n",
    "    if new_ids is not None:\n",
    "        return pd.DataFrame({'id': new_ids, 'quality_score': predictions})\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons Learned\n",
    "\n",
    "This model achieved a decent score on the public leaderboard (0.10676) but performed poorly on the private leaderboard due to:\n",
    "- **Overfitting to public data**: Features like `log_defect_area` and time-based features caused overfitting.\n",
    "- **LinearSVR limitations**: The dataset was non-linear, and LinearSVR was not the best choice.\n",
    "- **Lack of model diversity**: Adding non-linear models like LightGBM or SVR with RBF kernel could have improved performance.\n",
    "\n",
    "For future competitions, consider:\n",
    "- Analyzing data distribution to choose appropriate models.\n",
    "- Using more diverse models in the ensemble.\n",
    "- Avoiding features that may overfit to the public test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}